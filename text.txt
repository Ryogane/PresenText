//私たちは半自動抵抗仕分け機というものを作成しました。

電子工作をする際に抵抗をいくつか出しても、どれがどの抵抗なのかわからなくなったり、視力の低下などによりカラーコードが読めなかったりすることがあると思います。

そこで自動で選別してくれる装置があるといいですよね。


今回、この問題を解決するため２つのAPIを使用しました。

ます１つ目が、選別する抵抗値を指定するWebページを作成するために、googleのfirebaseを使いました。

そして２つ目に今回メインとしてMicrosoftのCustomVisionServiceを使いました。

CustomVisionServiceとは大量の画像をタグづけをして送信することで機械学習をさせることができるものです。

学習させたデータをもとに、ある選別対象の画像を送信するとその画像がタグのうちの何であるか返してくれます。

今回は抵抗の画像を学習させました。






ではマシンの動作の流れです。


まずWebページから、これからどの抵抗を選別するのかを登録します。

そして抵抗を一つステージに置き、ボタンを押します。

するとラズパイが写真を撮影し、画像をトリミングします。

そしてCustomVisionServiceへ画像を送信して何Ωの抵抗であるか調べます。

CustomVisionServiceで出た結果から、Webページで登録したものと同じであるかそうでないかで振り分けをします。

もし結果が同じならばステージは右側へ傾き、違うのならステージは左側へ傾きます。

これで今使いたい抵抗なのか、そうでないものなのかを仕分けることができます。


この装置は光の加減で結果が大きく左右されてしまいます。
なので今日は実機ではなく映像の方をデモをやらせていただきます。



デモ映像ーーーーーーーーーーーーーーーー

これから抵抗５つを仕分けていきます。

使いたい抵抗の対象は５６０Ωで設定しています。

５つのうち３つが５６０Ω、残り２つは１５０ｋΩと　６５０Ωと設定したものとは違う抵抗を混ぜます。

違うものは、初めと最後に判別させます。

まず１つめは設定とは違うため左側へ。

２つ目３つ目４つ目は設定した５６０Ωなので右側へ傾きました。

そして最後の抵抗は設定のものとは違うため左へ傾きました。

このようにして、今使いたい抵抗のみを抽出することができます。


ーーーーーーーーーーーー

このCustomVisionServiceを扱う上で苦労した点が精度の問題です。

ラズパイで撮影した画像そのままを使い　学習　と　判定　をしてしまうと余分なところも入ってしまうせいか精度が出ませんでした。

そこで精度を上げるため学習素材を抵抗の部分のみにし、ラズパイで撮影する画像も抵抗の部分のみをopenCVの物体検出を使い、切り出すようにしたところ精度が向上しました。




精度が向上したと言っても、やはりまだ精度は低いですが、もっとたくさん学習させて確実に仕分けられるようにしたいです。
また、分けられる種類も増やしていけたらなと思います。

以上です。
ありがとうございました。
